{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0DJ4kaFczll/TTWRx1TcY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TOKTAK007/Alexnet-with-TOKTAK/blob/main/Alexnet_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqXMzxAnqrkb"
      },
      "outputs": [],
      "source": [
        "#Set environment\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในการสร้างโมเดล Machine Learning หรือ Deep Learning ส่วนใหญ่จะใช้ข้อมูลสำหรับการสร้างโมเดลเป็นชุดเดียว แต่ในขั้นตอนการสร้างโมเดลนั้น เราจะแบ่งชุดข้อมูลนั้นออกเป็น 2 ชุด คือ Training set และ Validation set\n",
        "\n",
        "Training set คือชุดข้อมูลที่ใช้สำหรับการสร้างโมเดล โมเดลจะถูก train ด้วยชุดข้อมูลนี้โดยใช้ algorithm หรือโมเดลที่เราได้เลือกไว้ เพื่อให้โมเดลเรียนรู้วิธีการแยกแยะระหว่างแบบฝึกหัด (training data) ที่ต่างกันอย่างไร\n",
        "\n",
        "Validation set คือชุดข้อมูลที่เอาไว้ใช้ตรวจสอบประสิทธิภาพของโมเดลที่ได้ train แล้ว โดย Validation set จะไม่ถูกนำไป train โมเดลแต่จะถูกนำไปใช้ในการประเมินว่าโมเดลที่เราได้สร้างขึ้นมามีความแม่นยำในการทำนายข้อมูลดีหรือไม่ ด้วยการเทียบผลการทำนายกับคำตอบจริงของ Validation set\n",
        "\n",
        "สรุปกันย่อ ๆ คือ Training set เอาไว้สำหรับ train model และ Validation set เอาไว้ใช้ในการประเมินคุณภาพของโมเดลที่ได้ train ขึ้นมาด้วยการทำนายข้อมูลที่ไม่เคยเห็น (unseen data) ก่อนที่จะนำโมเดลไปใช้งานจริง\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "d6eGfSj4skln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "img_dim เป็นตัวแปรที่ใช้เก็บค่าขนาดของรูปภาพ โดยในที่นี้ img_dim = 32 หมายถึงขนาดของรูปภาพเป็น 32x32 pixel (หรือกว้าง 32 พิกเซล ยาว 32 พิกเซล) โดยรูปภาพนี้มี 3 ช่องสี (RGB) ดังนั้นขนาดของรูปภาพทั้งหมดคือ 32x32x3 (หรือ 3072)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6ac5jc__5Lgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 0: Predefined Parameters.\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "datasets_path = '/Users/user/Desktop/test/input_data/datasets'\n",
        "train_size = 0.7; val_size = 0.2; test_size = 0.1\n",
        "seed = 42\n",
        "batch_size = 32\n",
        "model_name = 'TOKTAK'\n",
        "\n",
        "checkpoint_path = '/Users/user/Desktop/test/input_data/train_model/' + model_name + '.ckpt'\n",
        "output_dim = 2\n",
        "image_dim_1 = 32; image_dim_2 = 32\n",
        "epochs = 20\n",
        "image2plot = 10"
      ],
      "metadata": {
        "id": "JaI6t0A4ruiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Splitting the Dataset and Viewing Images. \n",
        "\n",
        "# class_names = os.listdir(datasets_path)\n",
        "class_names = [f.name for f in os.scandir(datasets_path) if f.is_dir() and not f.name.startswith('.')]\n",
        "print('class names: ', class_names)\n",
        "num_class = len(class_names)\n",
        "image_files=glob.glob(datasets_path + '/*/*.png', recursive=True)\n",
        "\n",
        "print('total images in: ', datasets_path, ' is ', len(image_files))\n",
        "\n",
        "idx_to_class = {i:j for i, j in enumerate(class_names)}\n",
        "class_to_idx = {value:key for key, value in idx_to_class.items()}\n",
        "train_idx, test_idx, val_idx = random_split(image_files, [train_size, val_size, test_size])\n",
        "train_list=[image_files[i] for i in train_idx.indices]\n",
        "val_list=[image_files[i] for i in test_idx.indices]\n",
        "test_list=[image_files[i] for i in val_idx.indices]\n",
        "\n",
        "print('number of training images: ', len(train_list),\n",
        "\t'\\nnumber of val images: ', len(val_list),\n",
        "\t'\\nnumber of test images: ', len(test_list))\n",
        "\n",
        "def view_images(train_list, num_class):\n",
        "\tnum_rows = 5; num_cols = 5\n",
        "\tnum_images = num_rows * num_cols\n",
        "\tfig, axes = plt.subplots(num_rows, num_cols)\n",
        "\tdisplayed_classes = set()\n",
        "\twhile len(displayed_classes) < num_class:\n",
        "\t\trandom_images = random.sample(train_list, num_images)\n",
        "\t\tfor i, ax in enumerate(axes.flatten()):\n",
        "\t\t\timg_path = random_images[i]\n",
        "\t\t\timg = Image.open(img_path)\n",
        "\t\t\tclass_name = img_path.split('/')[-2]\n",
        "\t\t\tax.imshow(img)\n",
        "\t\t\tax.set_title(f'{class_name}')\n",
        "\t\t\tax.axis('off')\n",
        "\t\t\tdisplayed_classes.add(class_name)\n",
        "\tplt.tight_layout()\n",
        "\tplt.show()\n",
        "\n",
        "#view_images(train_list, num_class)"
      ],
      "metadata": {
        "id": "WMSTaZTVs-kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "โค้ด train_data_flat = train_data.reshape(train_data.shape[0], -1) เป็นการแปลงข้อมูลใน train_data จากรูปแบบ 3 มิติ (สูง, กว้าง, ลึก) เป็นข้อมูลแบบ 2 มิติ (จำนวนตัวอย่าง, จำนวนคุณสมบัติ) \n",
        "\n",
        "โดยใช้ฟังก์ชัน reshape ซึ่งเป็นฟังก์ชันของ NumPy\n",
        "\n",
        "การใช้ -1 ใน parameter ที่สองของ reshape จะหมายถึงการเปลี่ยนขนาดแกนที่สองของ train_data ให้เป็นขนาดที่เหมาะสมกับขนาดของข้อมูลที่กำลังจะเปลี่ยนแปลง (ในที่นี้คือ train_data.shape[0]) โดย reshape จะคำนวณขนาดแกนที่สองอัตโนมัติโดยให้เหมาะสมกับขนาดของข้อมูลที่กำลังจะเปลี่ยนแปลง\n",
        "\n",
        "ดังนั้น train_data_flat จะเป็น numpy array ของข้อมูลแบบ 2 มิติที่มีจำนวนตัวอย่างเท่ากับ train_data \n",
        "\n",
        "และจำนวนคุณสมบัติเท่ากับจำนวนพิกเซลของรูปภาพ โดยแต่ละตัวอย่างจะเป็นเวกเตอร์ของค่าพิกเซลทั้งหมดในรูปภาพที่มีขนาดเท่ากับจำนวนคุณสมบัติ\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "32uEPgbjwQr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Data Preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "\n",
        "def means_std(train_list):\n",
        "\ttrain_data = []\n",
        "\tfor img_path in train_list:\n",
        "\t\timg = io.imread(img_path)\n",
        "\t\timg = img / 255.0  # limit value to be between 0 and 1\n",
        "\t\ttrain_data.append(img)\n",
        "\ttrain_data = np.array(train_data)\n",
        "\ttrain_data = np.transpose(train_data, (0, 3, 1, 2))  # fit PyTorch format\n",
        "\ttrain_data_flat = train_data.reshape(train_data.shape[0], -1) #comment อยู่ด้านบน\n",
        "\tscaler = StandardScaler()\n",
        "\tscaler.fit(train_data_flat)\n",
        "\tmean = scaler.mean_.reshape(3, -1).mean(axis=1)\n",
        "\tstd = scaler.scale_.reshape(3, -1).std(axis=1)\n",
        "\tprint('mean: ', mean)\n",
        "\tprint('standard deviation: ', std)\n",
        "\treturn mean, std\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "class SatelliteDataset():\n",
        "\tdef __init__(self, image_paths, class_to_idx, transform=None):\n",
        "\t\tself.image_paths = image_paths\n",
        "\t\tself.class_to_idx = class_to_idx\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.image_paths)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\timage_filepath = self.image_paths[idx]\n",
        "\t\timage = Image.open(image_filepath)\n",
        "\t\tlabel = image_filepath.split('/')[-2]\n",
        "\t\tlabel = self.class_to_idx[label]\n",
        "\t\tif self.transform is not None:\n",
        "\t\t\timage = self.transform(image)\n",
        "\t\treturn image, label\n",
        "\n",
        "# mean, std = means_std(train_list)\n",
        "\n",
        "mean = [0.27140397, 0.28222303, 0.23752819]\n",
        "std = [0.00029074, 0.00028769, 0.00028466]\n",
        "\n",
        "flip = transforms.RandomHorizontalFlip()\n",
        "to_tensor = transforms.ToTensor()\n",
        "normalize = transforms.Normalize(mean, std)\n",
        "\n",
        "transform_train = transforms.Compose([flip, to_tensor, normalize])\n",
        "transform_val = transforms.Compose([to_tensor, normalize])\n",
        "transform_test = transforms.Compose([to_tensor, normalize])\n",
        "\n",
        "train_dataset = SatelliteDataset(train_list, class_to_idx, transform_train)\n",
        "val_dataset = SatelliteDataset(val_list, class_to_idx, transform_val)\n",
        "test_dataset = SatelliteDataset(test_list, class_to_idx, transform_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "    shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "    shuffle=False, drop_last=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "    shuffle=False, drop_last=False)\n",
        "\n",
        "# view_images(train_loader, num_class, class_names, mean=mean, std=std)"
      ],
      "metadata": {
        "id": "WEPPGdO-t5yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "คำสั่ง train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True) จะสร้าง DataLoader ของชุดข้อมูลการฝึก (training dataset) \n",
        "\n",
        "โดยใช้ข้อมูลจาก train_dataset ซึ่งสร้างจากขั้นตอนการแปลงรูปแบบของข้อมูลและการทำสเกล และกำหนด batch_size ของข้อมูลในแต่ละรอบการฝึก โดย shuffle=True จะทำให้ข้อมูลในแต่ละ batch ถูกสลับลำดับสุ่มใหม่เพื่อลดการเรียนรู้ลำดับของข้อมูลและป้องกันการเรียนรู้ pattern ที่ไม่ถูกต้องจากลำดับของข้อมูลเดิม และ drop_last=True จะทำให้ batch สุดท้ายที่ไม่เพียงพอสำหรับ batch_size จะถูกลบทิ้งเพื่อไม่ให้เกิดข้อผิดพลาดในการฝึก\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HmqNHWs70d5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "scaler.fit(train_data_flat) คือการฝึกหรือปรับแต่ง Scaler ด้วยข้อมูล training ที่ได้จากการแปลงข้อมูลรูปภาพเป็นเวกเตอร์ของค่าพิกเซลที่มีขนาดเท่ากับจำนวนคุณสมบัติ โดย Scaler เป็นเครื่องมือที่ใช้ในการปรับแต่งข้อมูลให้เหมาะสมกับการฝึกโมเดล โดยมักนิยมใช้ StandardScaler หรือ MinMaxScaler ในการปรับแต่งข้อมูล ซึ่ง StandardScaler จะปรับให้ข้อมูลมี mean ศูนย์และ standard deviation เท่ากับหนึ่ง ส่วน MinMaxScaler จะปรับให้ข้อมูลอยู่ในช่วง [0, 1]\n",
        "\n",
        "การทำ scaler.fit(train_data_flat) จะคำนวณค่า mean และ standard deviation หรือ min-max value ของแต่ละคุณสมบัติในข้อมูล training และเก็บไว้เพื่อใช้ในการปรับแต่งข้อมูลในขั้นตอนถัดไป เช่นการปรับแต่งข้อมูลในชุดข้อมูล validation หรือ test ก่อนนำข้อมูลมาฝึกโมเดล หรือในการใช้โมเดลจริง ๆ ในการทำนายข้อมูลจริง ๆ ดังนั้นการปรับแต่งข้อมูลด้วย Scaler เป็นส่วนสำคัญของการประมวลผลและการฝึกโมเดลที่มีประสิทธิภาพสูง\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "39oQ98dax8oQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "คำสั่ง mean = scaler.mean_.reshape(3, -1).mean(axis=1) เป็นการหาค่าเฉลี่ยของ mean ของแต่ละ feature โดยใช้ Scaler ที่เคยถูกปรับแต่งด้วยข้อมูล training ที่ผ่านการแปลงรูปแบบการสเกลข้อมูลใหม่แล้ว \n",
        "\n",
        "โดยการเรียกใช้ scaler.mean_ จะเป็นการเรียกค่า mean ของแต่ละ feature ที่ถูกปรับแต่งไว้ และ reshape(3, -1) จะเป็นการแบ่งค่า mean นี้ออกเป็น 3 ส่วน โดยแบ่งแต่ละ feature ให้อยู่ในแถวแยกกัน ซึ่งจะเห็นได้จากการกำหนดให้มี 3 แถว (rows) และ -1 ใน column ที่ไม่ระบุขนาด จะทำให้คำนวณค่า mean ของแต่ละ feature ในแต่ละแถว จากนั้นใช้ mean(axis=1) เพื่อหาค่าเฉลี่ยของแต่ละแถว ซึ่งจะได้เป็นเวกเตอร์ของค่าเฉลี่ย mean ของแต่ละ feature ในชุดข้อมูล training นั้น ๆ\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CsEdEfN_y_K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Model Initialization and Setup. \n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\tdef __init__(self, output_dim):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.features = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(3, 64, 3, 2, 1),  # in_channels(3RGB), out_channels(64 filter), kernel_size, stride, padding\n",
        "\t\t\tnn.MaxPool2d(2),  # kernel_size\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Conv2d(64, 192, 3, padding=1),\n",
        "\t\t\tnn.MaxPool2d(2),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Conv2d(192, 384, 3, padding=1),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Conv2d(384, 256, 3, padding=1),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Conv2d(256, 256, 3, padding=1),\n",
        "\t\t\tnn.MaxPool2d(2),\n",
        "\t\t\tnn.ReLU(inplace=True)\n",
        "\t\t)\n",
        "\t\tself.classifier = nn.Sequential(\n",
        "\t\t\tnn.Dropout(0.5),\n",
        "\t\t\tnn.Linear(256 * 2 * 2, 4096),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Dropout(0.5),\n",
        "\t\t\tnn.Linear(4096, 4096),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Linear(4096, output_dim),\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.features(x)\n",
        "\t\th = x.view(x.shape[0], -1)\n",
        "\t\tx = self.classifier(h)\n",
        "\t\treturn x, h\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "model = AlexNet(output_dim)\n",
        "\n",
        "summary(model, (3, image_dim_1, image_dim_2))\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "kSlctOXfx6hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "self.classifier เป็นชุดของเลเยอร์ (layer) ที่ใช้ในการประมวลผลขั้นต่อไปหลังจากการทำ feature extraction ด้วยชุดเลเยอร์ที่อยู่ใน self.features ที่กล่าวไปก่อนหน้านี้\n",
        "\n",
        "\n",
        "nn.Dropout(0.5) เป็นการใช้ dropout ที่จะทำให้บางโหนดในชุดข้อมูลถูกลบออกจากการคำนวณทุกครั้งที่ทำการสุ่มสลับชุดข้อมูล เพื่อป้องกัน overfitting\n",
        "\n",
        "\n",
        "nn.Linear(256 * 2 * 2, 4096) เป็นชั้นเลเยอร์เชิงเส้น (linear layer) ที่มีจำนวน output units เท่ากับ 4096 โดย input units จะมีขนาด 256 * 2 * 2 (256 คือจำนวน filters ที่ใช้ในชุดเลเยอร์ self.features และ 2x2 คือขนาดของ feature map หลังจากที่ผ่านชุดเลเยอร์ Convolutional และ Max Pooling)\n",
        "nn.ReLU(inplace=True) เป็นการใช้ ReLU activation function ในการ activate output units จากชั้นเลเยอร์ก่อนหน้า\n",
        "nn.Dropout(0.5) เช่นเดียวกับข้างบน\n",
        "nn.Linear(4096, 4096) เป็นชั้นเลเยอร์เชิงเส้นที่มี input units เท่ากับ 4096 (จำนวน output units จากชั้นก่อนหน้า) \n",
        "\n",
        "\n",
        "และ output units เท่ากับ 4096\n",
        "nn.ReLU(inplace=True) เช่นเดียวกับข้างบน\n",
        "nn.Linear(4096, output_dim) เป็นชั้นเลเยอร์เชิงเส้นสุดท้ายที่จะคำนวณ output ของโมเดล โดย output units จะมีจำนวนเท่ากับ output_dim ซึ่งเป็นจำนวน class ของปัญหาที่ต้องการจะทำนาย\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T-HZrRVV64rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "ฟังก์ชั่น forward ใช้สำหรับ forward pass ของโมเดล โดยทำการทำภาพผ่านชั้น self.features ซึ่งเป็นชั้นของโมเดล AlexNet ที่ใช้สำหรับการคัดแยกลักษณะของภาพ (feature extraction) \n",
        "\n",
        "\n",
        "จากนั้นแปลง output จากชั้น self.features เป็น vector แบบ 1 มิติ โดยการใช้ view แล้วนำไปผ่านชั้น self.classifier ซึ่งเป็นชั้น Fully Connected Layer เพื่อทำการคาดคะเนผลลัพธ์ของแต่ละ class จาก vector นั้น โดย output จะประกอบด้วยค่าที่คาดคะเนได้และ feature vector นั้นๆ ที่ได้จาก self.features\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p8bHd0eg95zV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "ฟังก์ชั่น calculate_accuracy ใช้สำหรับคำนวณความแม่นยำของโมเดล โดยรับ input สองตัวคือ y_pred และ y ที่เป็น tensor ที่มีขนาดเท่ากัน ซึ่งตัวแปร y_pred จะเก็บผลลัพธ์ที่ได้จากโมเดล และตัวแปร y จะเก็บ label จริงๆของข้อมูลตัวอย่าง\n",
        "\n",
        "\n",
        "ฟังก์ชั่นจะทำการคำนวณว่าโมเดลทำนายถูกต้องกี่ตัวด้วยการหาค่า top_pred ซึ่งจะเป็นตัวเลขที่เก็บค่า label ที่โมเดลคาดว่าจะเป็น label จริง จากนั้นจึงนำ top_pred มาเปรียบเทียบกับ y เพื่อหาว่าโมเดลทำนายถูกหรือไม่ ด้วยการใช้ eq และ sum ในการหาจำนวนของ label ที่โมเดลทำนายถูกต้อง และหลังจากนั้นจึงคำนวณค่าความแม่นยำโดยหารจำนวน label ทั้งหมดของข้อมูลตัวอย่าง และคืนค่าความแม่นยำออกมา\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "utK3zEcIBXka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Training the Model.\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "\ttop_pred = y_pred.argmax(1, keepdim=True)\n",
        "\tcorrect = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "\tacc = correct.float() / y.shape[0]\n",
        "\treturn acc\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "\tepoch_loss = 0; epoch_acc = 0\n",
        "\tmodel.train()\n",
        "\tfor (x, y) in tqdm(iterator, desc='Training', leave=False):\n",
        "\t\tx = x.to(device)\n",
        "\t\ty = y.to(device)\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\ty_pred, _ = model(x)\n",
        "\t\tloss = criterion(y_pred, y)\n",
        "\t\tacc = calculate_accuracy(y_pred, y)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tepoch_loss += loss.item()\n",
        "\t\tepoch_acc += acc.item()\n",
        "\treturn epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "\tepoch_loss = 0; epoch_acc = 0\n",
        "\tmodel.eval()\n",
        "\twith torch.no_grad():\n",
        "\t\tfor (x, y) in tqdm(iterator, desc='Evaluating', leave=False):\n",
        "\t\t\tx = x.to(device)\n",
        "\t\t\ty = y.to(device)\n",
        "\t\t\ty_pred, _ = model(x)\n",
        "\t\t\tloss = criterion(y_pred, y)\n",
        "\t\t\tacc = calculate_accuracy(y_pred, y)\n",
        "\t\t\tepoch_loss += loss.item()\n",
        "\t\t\tepoch_acc += acc.item()\n",
        "\treturn epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "\telapsed_time = end_time - start_time\n",
        "\telapsed_mins = int(elapsed_time / 60)\n",
        "\telapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "\treturn elapsed_mins, elapsed_secs\n",
        "\n",
        "def loss_history_plot(history_train, history_valid, model_name):\n",
        "\taxis_x = np.linspace(0, len(history_train), len(history_train))\n",
        "\tplt.plot(axis_x, history_train, linestyle='solid',\n",
        "\t\t\t color='red', linewidth=1, marker='o', ms=5, label='train')\n",
        "\tplt.plot(axis_x, history_valid, linestyle='solid',\n",
        "\t\t\t color='blue', linewidth=1, marker='o', ms=5, label='valid')\n",
        "\tplt.xlabel('epoch')\n",
        "\tplt.ylabel('loss')\n",
        "\tplt.legend(['train', 'valid'])\n",
        "\tplt.title(model_name + ': ' + 'Accuracy', fontweight='bold')\n",
        "\t# plt.savefig('data_out/' + 'resnet' + '.svg', format='svg', bbox_inches='tight', transparent=True, pad_inches=0)\n",
        "\tplt.show()\n",
        "\n",
        "\n",
        "history_train_loss = []\n",
        "history_valid_loss = []\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.monotonic()\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, val_loader, criterion, device)\n",
        "    history_train_loss.append(train_loss)\n",
        "    history_valid_loss.append(valid_loss)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "    end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "loss_history_plot(history_train_loss, history_valid_loss, model_name)\n"
      ],
      "metadata": {
        "id": "2SEQSeFw7Gqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "ค้ดบรรทัดนี้จะกำหนดค่าตั้งต้นให้กับตัวแปร best_valid_loss ด้วยค่า infinity (ได้มาจากฟังก์ชัน float() ที่ไม่มีการส่งค่าอะไรเข้าไป) ซึ่งจะถูกใช้ในการเก็บค่า loss ที่ดีที่สุดของ \n",
        "\n",
        "validation set ในแต่ละ epoch ถ้าหากค่า loss ของ validation set ใน epoch ปัจจุบันน้อยกว่าค่า loss ของ validation set ที่ดีที่สุดที่เคยเก็บไว้ \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "(best_valid_loss) จะทำการอัพเดท best_valid_loss ด้วยค่า loss ของ validation set ใน epoch ปัจจุบัน และบันทึกโมเดลที่ดีที่สุดไว้ในไฟล์ checkpoint_path\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0bHPeV9xGBXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "ฟังก์ชัน train เป็นฟังก์ชันสำหรับการฝึก (training) โมเดลของเรา โดยรับพารามิเตอร์ดังนี้\n",
        "\n",
        "model: โมเดลที่จะฝึก\n",
        "\n",
        "iterator: ตัวเลข (iterator) ที่จะใช้ในการวน loop ในการดึงข้อมูล (data) จาก dataloader โดยในแต่ละ iteration จะส่งคืน tensor ของ feature และ label\n",
        "optimizer: ออบเจกต์ Optimizer ที่ใช้ในการปรับพารามิเตอร์ของโมเดล\n",
        "\n",
        "criterion: ค่าความผิดพลาดที่ใช้ในการคำนวณ \n",
        "\n",
        "gradient และ loss\n",
        "\n",
        "device: ส่วนของ hardware (CPU หรือ GPU) ที่ใช้ในการฝึกโมเดล\n",
        "\n",
        "ฟังก์ชันจะส่งคืนค่าเฉลี่ยของ loss และ accuracy ของโมเดลที่ถูกคำนวณจากข้อมูลทั้งหมดใน iterator โดยในแต่ละ iteration จะทำการ forward ข้อมูลผ่านโมเดล คำนวณ loss และ accuracy จากนั้นทำการ backward และปรับค่าพารามิเตอร์ใน optimizer ตามที่ได้คำนวณไว้ และสะสมค่า loss และ accuracy ในแต่ละ iteration โดยใช้เทคนิค gradient descent ในการปรับพารามิเตอร์ของโมเดล สุดท้ายฟังก์ชันจะส่งคืนค่าเฉลี่ยของ loss และ accuracy ที่ถูกคำนวณจากข้อมูลทั้งหมดใน iterator\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VTFh9QOACXmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "tqdm เป็นโมดูลของ Python ที่ใช้สร้าง progress bar ในการแสดงผลการทำงานของ loop หรือ iterator ที่กำลังทำงานอยู่ เพื่อให้ผู้ใช้งานสามารถเห็นความคืบหน้าได้ง่ายขึ้น \n",
        "\n",
        "โดยจะแสดงเป็นเส้นตารางด้วยสีพื้นหลังเขียวที่แสดงถึงความคืบหน้าของการทำงาน สามารถติดตั้งได้ผ่าน pip หรือ conda และใช้งานได้ง่ายและสะดวก\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uGZfu9qADY1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "ฟังก์ชัน loss_history_plot นี้ใช้สำหรับพล็อตกราฟแสดงค่า loss ของการเทรนโมเดลในแต่ละ epoch ของชุดข้อมูล train และ validation โดยรับ parameter ดังนี้\n",
        "\n",
        "\n",
        "history_train: คือ list ที่เก็บค่า loss ของการเทรนโมเดลในแต่ละ epoch ของชุดข้อมูล train\n",
        "history_valid: คือ list ที่เก็บค่า loss ของการเทรนโมเดลในแต่ละ epoch ของชุดข้อมูล validation\n",
        "\n",
        "model_name: ชื่อของโมเดลที่ใช้เทรน\n",
        "ฟังก์ชันนี้จะสร้างกราฟแสดงค่า loss ของการเทรนโมเดลในแต่ละ epoch ของชุดข้อมูล train และ validation โดยใช้ matplotlib.pyplot ในการพล็อตกราฟ และแสดงผลผ่านทาง plt.show()\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TDJ0DTsaExZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "โค้ดนี้เป็นการ train โมเดล neural network โดยใช้ฟังก์ชัน train และ evaluate ซึ่งรับอินพุตเป็นโมเดลที่ต้องการ train, ชุดข้อมูลที่ใช้ train (train_loader), optimizer, criterion และ device ที่ใช้ในการ train โมเดล โดยจะวนลูปผ่านจำนวน epochs ที่กำหนดไว้ \n",
        "\n",
        "\n",
        "และเก็บค่า train loss และ validation loss ไว้ในตัวแปร history_train_loss และ history_valid_loss ตามลำดับ ในแต่ละ epoch จะทำการประมวลผล train loss, train accuracy, validation loss และ validation accuracy แล้วแสดงผลทางหน้าจอ และบันทึกโมเดลที่ให้ผลลัพธ์ validation loss ที่ดีที่สุดไว้ในไฟล์ที่กำหนด \n",
        "\n",
        "\n",
        "ท้ายสุดจะทำการพล็อตกราฟ loss ของ train และ validation ด้วยฟังก์ชัน loss_history_plot ซึ่งเป็นการพล็อตกราฟแสดงการเปลี่ยนแปลง loss ของ train และ validation ตามจำนวน epoch ที่ train โมเดล\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EUAstmjYFuGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5: Plotting Confusion Matrix.\n",
        "from sklearn import metrics\n",
        "\n",
        "def plot_confusion_matrix_CIFAR10(labels, pred_labels, classes):\n",
        "\tfig = plt.figure()\n",
        "\tax = fig.add_subplot(1, 1, 1)\n",
        "\tcm = metrics.confusion_matrix(labels, pred_labels)\n",
        "\tcm = metrics.ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "\tcm.plot(values_format='d', cmap='Greens', ax=ax)\n",
        "\t# plt.savefig('data_out/' + 'CM_resnet' + '.svg', format='svg', bbox_inches='tight', transparent=True, pad_inches=0)\n",
        "\tplt.show()\n",
        "\n",
        "import torch.nn.functional as TF\n",
        "\n",
        "def get_predictions(model, iterator, device):\n",
        "\tmodel.eval()\n",
        "\timages = []; labels = []; probs = []\n",
        "\twith torch.no_grad():\n",
        "\t\tfor (x, y) in iterator:\n",
        "\t\t\tx = x.to(device)\n",
        "\t\t\ty_pred, _ = model(x)\n",
        "\t\t\ty_prob = TF.softmax(y_pred, dim=-1)\n",
        "\t\t\timages.append(x.cpu())\n",
        "\t\t\tlabels.append(y.cpu())\n",
        "\t\t\tprobs.append(y_prob.cpu())\n",
        "\timages = torch.cat(images, dim=0)\n",
        "\tlabels = torch.cat(labels, dim=0)\n",
        "\tprobs = torch.cat(probs, dim=0)\n",
        "\treturn images, labels, probs\n",
        "\n",
        "model.load_state_dict(torch.load(checkpoint_path))\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "images, labels, probs = get_predictions(model, test_loader, device)\n",
        "pred_labels = torch.argmax(probs, 1)\n",
        "plot_confusion_matrix_CIFAR10(labels, pred_labels, class_names)"
      ],
      "metadata": {
        "id": "lT7eT11GHYdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nOmTwb5x2Kb6"
      }
    }
  ]
}