{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRDVOSkzaMnv1+7QP1+xd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TOKTAK007/Alexnet-with-TOKTAK/blob/main/Alexnet_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqXMzxAnqrkb"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "#Step 0: Predefined Parameters.\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "datasets_path = '/Users/user/Desktop/test/input_data/datasets'\n",
        "train_size = 0.7; val_size = 0.2; test_size = 0.1\n",
        "seed = 42\n",
        "batch_size = 32\n",
        "model_name = 'TOKTAK'\n",
        "\n",
        "checkpoint_path = '/Users/user/Desktop/test/input_data/train_model/' + model_name + '.ckpt'\n",
        "output_dim = 2\n",
        "image_dim_1 = 32; image_dim_2 = 32\n",
        "epochs = 20\n",
        "image2plot = 10\n",
        "\n",
        "#Step 1: Splitting the Dataset and Viewing Images. \n",
        "\n",
        "# class_names = os.listdir(datasets_path)\n",
        "class_names = [f.name for f in os.scandir(datasets_path) if f.is_dir() and not f.name.startswith('.')]\n",
        "print('class names: ', class_names)\n",
        "num_class = len(class_names)\n",
        "image_files=glob.glob(datasets_path + '/*/*.png', recursive=True)\n",
        "\n",
        "print('total images in: ', datasets_path, ' is ', len(image_files))\n",
        "\n",
        "idx_to_class = {i:j for i, j in enumerate(class_names)}\n",
        "class_to_idx = {value:key for key, value in idx_to_class.items()}\n",
        "train_idx, test_idx, val_idx = random_split(image_files, [train_size, val_size, test_size])\n",
        "train_list=[image_files[i] for i in train_idx.indices]\n",
        "val_list=[image_files[i] for i in test_idx.indices]\n",
        "test_list=[image_files[i] for i in val_idx.indices]\n",
        "\n",
        "print('number of training images: ', len(train_list),\n",
        "\t'\\nnumber of val images: ', len(val_list),\n",
        "\t'\\nnumber of test images: ', len(test_list))\n",
        "\n",
        "def view_images(train_list, num_class):\n",
        "\tnum_rows = 5; num_cols = 5\n",
        "\tnum_images = num_rows * num_cols\n",
        "\tfig, axes = plt.subplots(num_rows, num_cols)\n",
        "\tdisplayed_classes = set()\n",
        "\twhile len(displayed_classes) < num_class:\n",
        "\t\trandom_images = random.sample(train_list, num_images)\n",
        "\t\tfor i, ax in enumerate(axes.flatten()):\n",
        "\t\t\timg_path = random_images[i]\n",
        "\t\t\timg = Image.open(img_path)\n",
        "\t\t\tclass_name = img_path.split('/')[-2]\n",
        "\t\t\tax.imshow(img)\n",
        "\t\t\tax.set_title(f'{class_name}')\n",
        "\t\t\tax.axis('off')\n",
        "\t\t\tdisplayed_classes.add(class_name)\n",
        "\tplt.tight_layout()\n",
        "\tplt.show()\n",
        "\n",
        "# view_images(train_list, num_class)\n",
        "\n",
        "\n",
        "#Step 2: Data Preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "\n",
        "def means_std(train_list):\n",
        "\ttrain_data = []\n",
        "\tfor img_path in train_list:\n",
        "\t\timg = io.imread(img_path)\n",
        "\t\timg = img / 255.0  # limit value to be between 0 and 1\n",
        "\t\ttrain_data.append(img)\n",
        "\ttrain_data = np.array(train_data)\n",
        "\ttrain_data = np.transpose(train_data, (0, 3, 1, 2))  # fit PyTorch format\n",
        "\ttrain_data_flat = train_data.reshape(train_data.shape[0], -1)\n",
        "\tscaler = StandardScaler()\n",
        "\tscaler.fit(train_data_flat)\n",
        "\tmean = scaler.mean_.reshape(3, -1).mean(axis=1)\n",
        "\tstd = scaler.scale_.reshape(3, -1).std(axis=1)\n",
        "\tprint('mean: ', mean)\n",
        "\tprint('standard deviation: ', std)\n",
        "\treturn mean, std\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "class SatelliteDataset():\n",
        "\tdef __init__(self, image_paths, class_to_idx, transform=None):\n",
        "\t\tself.image_paths = image_paths\n",
        "\t\tself.class_to_idx = class_to_idx\n",
        "\t\tself.transform = transform\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.image_paths)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\timage_filepath = self.image_paths[idx]\n",
        "\t\timage = Image.open(image_filepath)\n",
        "\t\tlabel = image_filepath.split('/')[-2]\n",
        "\t\tlabel = self.class_to_idx[label]\n",
        "\t\tif self.transform is not None:\n",
        "\t\t\timage = self.transform(image)\n",
        "\t\treturn image, label\n",
        "\n",
        "# mean, std = means_std(train_list)\n",
        "\n",
        "mean = [0.27140397, 0.28222303, 0.23752819]\n",
        "std = [0.00029074, 0.00028769, 0.00028466]\n",
        "\n",
        "flip = transforms.RandomHorizontalFlip()\n",
        "to_tensor = transforms.ToTensor()\n",
        "normalize = transforms.Normalize(mean, std)\n",
        "transform_train = transforms.Compose([flip, to_tensor, normalize])\n",
        "transform_val = transforms.Compose([to_tensor, normalize])\n",
        "transform_test = transforms.Compose([to_tensor, normalize])\n",
        "train_dataset = SatelliteDataset(train_list, class_to_idx, transform_train)\n",
        "val_dataset = SatelliteDataset(val_list, class_to_idx, transform_val)\n",
        "test_dataset = SatelliteDataset(test_list, class_to_idx, transform_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "    shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "    shuffle=False, drop_last=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "    shuffle=False, drop_last=False)\n",
        "\n",
        "# view_images(train_loader, num_class, class_names, mean=mean, std=std)\n",
        "\n",
        "#Step 3: Model Initialization and Setup. \n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\tdef __init__(self, output_dim):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.features = nn.Sequential(\n",
        "\t\t\tnn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
        "\t\t\tnn.MaxPool2d(2),  # kernel_size\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Conv2d(64, 192, 3, padding=1),\n",
        "\t\t\tnn.MaxPool2d(2),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Conv2d(192, 384, 3, padding=1),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Conv2d(384, 256, 3, padding=1),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Conv2d(256, 256, 3, padding=1),\n",
        "\t\t\tnn.MaxPool2d(2),\n",
        "\t\t\tnn.ReLU(inplace=True)\n",
        "\t\t)\n",
        "\t\tself.classifier = nn.Sequential(\n",
        "\t\t\tnn.Dropout(0.5),\n",
        "\t\t\tnn.Linear(256 * 2 * 2, 4096),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Dropout(0.5),\n",
        "\t\t\tnn.Linear(4096, 4096),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Linear(4096, output_dim),\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.features(x)\n",
        "\t\th = x.view(x.shape[0], -1)\n",
        "\t\tx = self.classifier(h)\n",
        "\t\treturn x, h\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "model = AlexNet(output_dim)\n",
        "\n",
        "summary(model, (3, image_dim_1, image_dim_2))\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Step 4: Training the Model.\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "\ttop_pred = y_pred.argmax(1, keepdim=True)\n",
        "\tcorrect = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "\tacc = correct.float() / y.shape[0]\n",
        "\treturn acc\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "\tepoch_loss = 0; epoch_acc = 0\n",
        "\tmodel.train()\n",
        "\tfor (x, y) in tqdm(iterator, desc='Training', leave=False):\n",
        "\t\tx = x.to(device)\n",
        "\t\ty = y.to(device)\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\ty_pred, _ = model(x)\n",
        "\t\tloss = criterion(y_pred, y)\n",
        "\t\tacc = calculate_accuracy(y_pred, y)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tepoch_loss += loss.item()\n",
        "\t\tepoch_acc += acc.item()\n",
        "\treturn epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "\tepoch_loss = 0; epoch_acc = 0\n",
        "\tmodel.eval()\n",
        "\twith torch.no_grad():\n",
        "\t\tfor (x, y) in tqdm(iterator, desc='Evaluating', leave=False):\n",
        "\t\t\tx = x.to(device)\n",
        "\t\t\ty = y.to(device)\n",
        "\t\t\ty_pred, _ = model(x)\n",
        "\t\t\tloss = criterion(y_pred, y)\n",
        "\t\t\tacc = calculate_accuracy(y_pred, y)\n",
        "\t\t\tepoch_loss += loss.item()\n",
        "\t\t\tepoch_acc += acc.item()\n",
        "\treturn epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "\telapsed_time = end_time - start_time\n",
        "\telapsed_mins = int(elapsed_time / 60)\n",
        "\telapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "\treturn elapsed_mins, elapsed_secs\n",
        "\n",
        "def loss_history_plot(history_train, history_valid, model_name):\n",
        "\taxis_x = np.linspace(0, len(history_train), len(history_train))\n",
        "\tplt.plot(axis_x, history_train, linestyle='solid',\n",
        "\t\t\t color='red', linewidth=1, marker='o', ms=5, label='train')\n",
        "\tplt.plot(axis_x, history_valid, linestyle='solid',\n",
        "\t\t\t color='blue', linewidth=1, marker='o', ms=5, label='valid')\n",
        "\tplt.xlabel('epoch')\n",
        "\tplt.ylabel('loss')\n",
        "\tplt.legend(['train', 'valid'])\n",
        "\tplt.title(model_name + ': ' + 'Accuracy', fontweight='bold')\n",
        "\t# plt.savefig('data_out/' + 'resnet' + '.svg', format='svg', bbox_inches='tight', transparent=True, pad_inches=0)\n",
        "\tplt.show()\n",
        "\n",
        "\n",
        "history_train_loss = []\n",
        "history_valid_loss = []\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.monotonic()\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, val_loader, criterion, device)\n",
        "    history_train_loss.append(train_loss)\n",
        "    history_valid_loss.append(valid_loss)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "    end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "loss_history_plot(history_train_loss, history_valid_loss, model_name)\n",
        "\n",
        "#Step 5: Plotting Confusion Matrix.\n",
        "from sklearn import metrics\n",
        "\n",
        "def plot_confusion_matrix_CIFAR10(labels, pred_labels, classes):\n",
        "\tfig = plt.figure()\n",
        "\tax = fig.add_subplot(1, 1, 1)\n",
        "\tcm = metrics.confusion_matrix(labels, pred_labels)\n",
        "\tcm = metrics.ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "\tcm.plot(values_format='d', cmap='Greens', ax=ax)\n",
        "\t# plt.savefig('data_out/' + 'CM_resnet' + '.svg', format='svg', bbox_inches='tight', transparent=True, pad_inches=0)\n",
        "\tplt.show()\n",
        "\n",
        "import torch.nn.functional as TF\n",
        "\n",
        "def get_predictions(model, iterator, device):\n",
        "\tmodel.eval()\n",
        "\timages = []; labels = []; probs = []\n",
        "\twith torch.no_grad():\n",
        "\t\tfor (x, y) in iterator:\n",
        "\t\t\tx = x.to(device)\n",
        "\t\t\ty_pred, _ = model(x)\n",
        "\t\t\ty_prob = TF.softmax(y_pred, dim=-1)\n",
        "\t\t\timages.append(x.cpu())\n",
        "\t\t\tlabels.append(y.cpu())\n",
        "\t\t\tprobs.append(y_prob.cpu())\n",
        "\timages = torch.cat(images, dim=0)\n",
        "\tlabels = torch.cat(labels, dim=0)\n",
        "\tprobs = torch.cat(probs, dim=0)\n",
        "\treturn images, labels, probs\n",
        "\n",
        "model.load_state_dict(torch.load(checkpoint_path))\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "images, labels, probs = get_predictions(model, test_loader, device)\n",
        "pred_labels = torch.argmax(probs, 1)\n",
        "plot_confusion_matrix_CIFAR10(labels, pred_labels, class_names)\n",
        "\n",
        "#Step 6: Plotting the Most Incorrect Prediction.\n",
        "\n",
        "def normalize_image(image):\n",
        "\timage_min = image.min()\n",
        "\timage_max = image.max()\n",
        "\timage.clamp_(min=image_min, max=image_max)\n",
        "\timage.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
        "\treturn image\n",
        "\n",
        "def plot_most_incorrect_CIFAR10(incorrect, classes, n_images, normalize=True):\n",
        "\trows = int(np.sqrt(n_images))\n",
        "\tcols = int(np.sqrt(n_images))\n",
        "\tfig = plt.figure()\n",
        "\tfor i in range(rows*cols):\n",
        "\t\tax = fig.add_subplot(rows, cols, i+1)\n",
        "\t\timage, true_label, probs = incorrect[i]\n",
        "\t\timage = image.permute(1, 2, 0)\n",
        "\t\ttrue_prob = probs[true_label]\n",
        "\t\tincorrect_prob, incorrect_label = torch.max(probs, dim=0)\n",
        "\t\ttrue_class = classes[true_label]\n",
        "\t\tincorrect_class = classes[incorrect_label]\n",
        "\t\tif normalize:\n",
        "\t\t\timage = normalize_image(image)\n",
        "\t\tax.imshow(image.cpu().numpy())\n",
        "\t\tax.set_title(f'true label: {true_class} ({true_prob:.3f})\\n'\n",
        "             f'pred label: {incorrect_class} ({incorrect_prob:.3f})',\n",
        "             fontsize=6)\n",
        "\t\tax.axis('off')\n",
        "\tfig.subplots_adjust(hspace=0.6)\n",
        "\t# plt.savefig('data_out/' + 'incorrect_resnet' + '.svg', format='svg', bbox_inches='tight', transparent=True, pad_inches=0)\n",
        "\tplt.show()\n",
        "\n",
        "corrects = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "for image, label, prob, correct in zip(images, labels, probs, corrects):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "incorrect_examples.sort(reverse = True, key=lambda x: torch.max(x[2], dim=0).values)\n",
        "if len(incorrect_examples) >= image2plot:\n",
        "\tplot_most_incorrect_CIFAR10(incorrect_examples, class_names, image2plot)\n",
        "else:\n",
        "    print('reduce the number of image2plot')\n",
        "\n",
        "\n"
      ]
    }
  ]
}